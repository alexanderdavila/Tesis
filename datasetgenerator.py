# -*- coding: utf-8 -*-
"""DatasetGenerator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gw7UBESt84b9zmh8LQp32kf_k_Rb6zil
"""

!pip install biopython

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
#from lib2to3.pygram import pattern_symbols
#from operator import concat
from re import S, split
#from turtle import pos
from Bio import SeqIO
from Bio.PDB import PDBList
import numpy as np
#import time
from collections import defaultdict
from itertools import *
from Bio.PDB.PDBParser import PDBParser
from Bio import *
import tensorflow as tf
import os
import random
#import gc
#import warnings
#import numpy as np
import rpy2.robjects.numpy2ri as rpyn
import itertools as it

from Bio import motifs 
from Bio.Seq import Seq 



# %load_ext rpy2.ipython
# %R install.packages("Peptides", dependencies=TRUE)
# %R library(Peptides)
n=19
numAdd=(n // 2)

'''Crear diccionario'''
def create_dictionary(aminoacids):
    dictionary=defaultdict(lambda: 20,zip(aminoacids,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]))
    return dictionary

aminoacids="DERKNHQSTAGVPLFYIMWC-"
diccionario=create_dictionary(aminoacids)


'''reading id's from pdb'''
def id_reading (file):
    fic = open(file, "r")
    lines = []
    for line in fic:
        lines.append(line)
    fic.close()
    PDBlist2=[]
    PDBlist2=lines[0].split(',')

    return PDBlist2

'''Selecting structures from PDB'''
def download_pdb(pdblist):
    pdbl = PDBList()

    for i in pdblist:
         pdbl.retrieve_pdb_file(i,pdir='/content/drive/MyDrive/Tesis/PDB',file_format="pdb") #-> str

'''read sequence from pdb'''
def read_sequence(pdblist):
    for list in pdblist:
        PDBFile = "/content/drive/MyDrive/Tesis/PDB/pdb"+list+".ent"
        with open(PDBFile, 'r') as pdb_file:
            for record in SeqIO.parse(pdb_file, 'pdb-atom'):
                pdb_file.close()
                return record.seq


'''Crea matriz nxn de ceros'''
def crear_matriz():
    array=np.zeros((21,21),dtype=float)
    return array


'''recorrer-secuencia distancia n'''
def recorrer_ventana(ventana,j,paso):
    var=ventana[j]

    tupla=[]
    for i in range(0,len(ventana)-paso):
        if ventana[i]==var:
            tupla.append(ventana[i])
            tupla.append(ventana[i+paso])
    return tupla

'''obtener coordenadas'''
def get_coordenadas(tupla):
    #print(tupla)
    item=[]
    for i in range(0,len(tupla)):
        for j in range(0,len(tupla[0])):
            item.append(diccionario[tupla[i][j]])

    return item

def element_exist(list,index):

    if list.count(list[index])>=2:
        flag=True
    else:
        flag=False
    return flag


def prepararSecuencia(sequence):
    complemento=list("-"*numAdd)
    sequence_complete=complemento+list(sequence)+complemento
    return sequence_complete

def pairwise(iterable):
    l=[]
    l=tee(iterable,n)
    for i in range(1,n):
      for a in range(i):
        next(l[i],None)
    return zip(*l)

def llenar_matriz(tupla,matriz):
    #print(tupla)
    init1=0
    init2=1
    x=tupla[init1]
    #print("imprimiendo x: "+str(x))
    y=tupla[init2]
    #print("imprimiendo y: "+str(y))
    for i in range(0,int(len(tupla)/2)):
        if matriz[x][y]==0:
            matriz[x][y]=1
            init1+=2
            init2+=2
        else:
            matriz[x][y]+=1
            init1+=2
            init2+=2
        if init2 <=len(tupla):
            x=tupla[init1]
            y=tupla[init2]
    #print(matriz)
    return matriz

def generar_matriz(ventana,matriz,paso):
    
    lista=[]
    for j in range(0,len(ventana)-1):
        lista.append(ventana[j])
        flag=element_exist(lista,j)
        if flag:
            continue
        else:
            if j < len(ventana)-paso: 
                tupla=recorrer_ventana(ventana,j,paso)
                matriz=llenar_matriz(tupla,matriz)
            #aqui debe generar las n matrices 
            #guardar en una lista y retornarlas
    return  matriz

#matrices=[]
def crear_matrices(ventana):
            
    # matriz1=crear_matriz()
    matrices=[]
    paso=7
    for i in range(1,paso+1):  
        matriz=crear_matriz() 
        matrizfinal=generar_matriz(ventana,matriz,i)
        matrices.append(matrizfinal)
        matriz=[]  
    #print(matrices)    
    return matrices

def get_iterator(sequence_original):
    ventaneo=pairwise(sequence_original)
    a=combinations(ventaneo,2)
    return a

def verificarConbinations(conb):
  cad=""
  cadR=""
  for va, vr in conb:
    p=va[9]
    q=vr[9]
    cad=cad+p
    cadR=cadR+q
  return cad, cadR

def contact_map(nameFile,u,Url):
    dist_matrix=create_dist_matrix(nameFile,u,Url)
    #contact_map=create_contact_map(dist_matrix)
    return dist_matrix

def create_dist_matrix(pdb_code,u,Url):
    parser=PDBParser()
    structure = parser.get_structure(pdb_code, Url)
    model = structure[0]
    dist_matrix = calc_dist_matrix (model ["A"], model ["A"],u)
    return dist_matrix

def calc_dist_matrix(chain_one, chain_two,u) :

    """Returns a matrix of C-alpha distances between two chains"""
    #print(u)
    answer = np.zeros((u, u), np.float)
    for row, residue_one in enumerate(chain_one) :
        if(row==u):
            break
        for col, residue_two in enumerate(chain_two) :
            valor=calc_residue_dist(residue_one, residue_two)
            #print("mat"+str(len(answer))+"COL---> "+str(col)+ "  ROW----->"+str(row) + "   VALOR-----> " + str(valor ) + "  U---->"+str(u))
            if(col==u):
                break
            answer[row, col] = valor
    return answer

dicContactos= defaultdict( list )


def calc_residue_dist(residue_one, residue_two) :
    """Returns the C-alpha distance between two residues"""
    try:
        diff_vector = residue_one["CA"].coord -residue_two["CA"].coord
        distance=0
        distance=np.sqrt(np.sum(diff_vector*diff_vector))
        replace=np.nan_to_num(distance,nan=-1)

        return replace
    except:
        return -1

def create_contact_map(distance_matrix) :
    # print(distance_matrix)
    # print("#####################################################################")
    # print("#####################################################################")
    distance_matrix[distance_matrix>15]=0.4
    # print(distance_matrix)
    # print("#####################################################################")
    # print("#####################################################################")
    distance_matrix[distance_matrix>10]=0.3
    # print(distance_matrix)
    # print("#####################################################################")
    # print("#####################################################################")
    distance_matrix[distance_matrix>8]=0.2
    # print(distance_matrix)
    # print("#####################################################################")
    # print("#####################################################################")
    distance_matrix[distance_matrix>1]=0.1
    # print(distance_matrix)
    # print("#####################################################################")
    # print("#####################################################################")
    return distance_matrix

# def obtenerDiccionario(nombreDiccionario,path):
#     new_dataset = tf.data.experimental.load(path)
#     for elem in new_dataset:
#         #print(elem[nombreDiccionario])
#         if(1==1):
#             break


def elegir_Random(datos, pesos):
    r = random.random()
    for i, p in enumerate(pesos):
        if p > r:
            break
    return datos[i]

matrices=[]

def get_secuencia(PDBFile):
   with open(PDBFile, 'r') as pdb_file:
        for record in SeqIO.parse(pdb_file, 'pdb-atom'):
            pdb_file.close()
   return record.seq

def _bytes_feature(value):
  """Returns a bytes_list from a string / byte."""
  if isinstance(value, type(tf.constant(0))):
    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.
  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))

def _float_feature(value):
  """Returns a float_list from a float / double."""
  return tf.train.Feature(float_list=tf.train.FloatList(value=value))

def _int64_feature(value):
  """Returns an int64_list from a bool / enum / int / uint."""
  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))

def serialize_example(matricesVa, matricesVr, distancia, propertiesVa,propertiesVr,pssm,clase):
  """
  Creates a tf.train.Example message ready to be written to a file.
  """
  # Create a dictionary mapping the feature name to the tf.train.Example-compatible
  # data type.
  feature = {
      'matricesVa': _float_feature(matricesVa),
      'matricesVr': _float_feature(matricesVr),
      'distancia': _float_feature([distancia]),
      'propertiesVa': _float_feature(propertiesVa),
      'propertiesVr': _float_feature(propertiesVr),
      'pssm': _float_feature(pssm),
      'clase':_float_feature(clase),     
  }
  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))
  return example_proto.SerializeToString()

def getCompositionR(st):
    vaStrvR=''.join(map(str, st))
#     %R ar<-'$vaStrvR'
    resul = %R vhseScales(ar)
    #print(list(resul[0]))
    return list(resul[0])

def getPssm(SeqA,SeqB):
  DNA_motif = [Seq(SeqA),Seq(SeqB)]
  motif = motifs.create(DNA_motif,alphabet="DERKNHQSTAGVPLFYIMWC-X") 

  motif.degenerate_consensus
  W = motif.pssm
  matriz=[]
  for i in W:
    l=[]
    for j in W[i]:    
      if(str(j)=='-inf'):
        l.append(-1.0)
      else:
        l.append(j)
    matriz.append(l)
  matriz=np.array(matriz).flatten()

  
  return matriz

def dist_encode(value):
    table={
        0:[1,0,0,0],
        1:[0,1,0,0],
        2:[0,0,1,0],
        3:[0,0,0,1],
        }
    if(value >=0 and value<8):
        return table[0]
    elif(value >=8 and value<10):
        return table[1]
    elif(value >=10 and value<15):
        return table[2]
    else:
        return table[3]

import tempfile




def main():
  #inicio=time.time()
  #leer la secuencia de la proteina
  rechazo=0.97
  ingreso=0.03
  datos = [0,1]
  peso = [rechazo,ingreso]
  clase_A=0
  clase_B=0
  clase_C=0
  clase_D=0
  
  clase_1=0
  clase_2=0
  clase_3=0
  clase_4=0

  conteoCeros=0
  conteoUnos=0

  pdblist=id_reading("/content/drive/MyDrive/Tesis/CURRENTPDB.txt")
  path="/content/drive/MyDrive/Tesis/dataset1000Protein.dat"
  #download_pdb(pdblist[35663:])
  with tf.io.TFRecordWriter(path) as file_writer:
    #for _ in range(100):
    for list in pdblist[:1000]:
      try:      
        print("Id Protein: "+str(list))
        
        PDBFile = "/content/drive/MyDrive/Tesis/PDB/pdb"+list+".ent"
        # contador=0
        sequence=get_secuencia(PDBFile)
        prepareSequence=prepararSecuencia(sequence)
        print(sequence)
        tamMatriz=len(sequence)
        print(tamMatriz)
        if tamMatriz>1000:
          continue
        contacMap=contact_map(list,tamMatriz,PDBFile)

        combinations=get_iterator(prepareSequence)
      
        #print(sequence)
        for i in range(len(sequence)-1):
          for j in range(i+1,len(sequence)):

            #*********************************************************************
            #                   CONTROL CEROS Y UNOS                             *
            #*********************************************************************

            if(conteoCeros>conteoUnos and (conteoCeros-conteoUnos)>50):
              peso = [rechazo+0.01,ingreso-0.01]
            else:
              if(conteoUnos>conteoCeros and (conteoUnos-conteoCeros)>50):
                peso = [rechazo-0.02,ingreso+0.02]

            # if((conteoCeros-conteoUnos)>50):
            #   peso = [rechazo+0.01,ingreso-0.01]
            # else:
            #   if(conteoUnos>conteoCeros and (conteoUnos-conteoCeros)>50):
            #     peso = [rechazo-0.02,ingreso+0.02]
            #**********************************************************************
            #**********************************************************************
            
            #*********************************************************************
            #                   RECORRIDO DE COMBINACIONES                       *
            #*********************************************************************        
            va,vr=next(combinations) 

            SVA=va[:]
            SVR=vr[:] 
            #**********************************************************************
            #**********************************************************************
            
            
            #*********************************************************************
            #                       CALCULAR DISTANCIA                           *
            #*********************************************************************
            distancia=j-i
            #print("distancia: "+str(distancia))

            contact=contacMap[i][j]
            #print(contact)

            ra=random.random()
            numeroRd = elegir_Random(datos, peso)
            clase=[]
            clase=dist_encode(contact)
            #print(clase)
            if((clase[3]==0) or (clase[3]!=0  and numeroRd==1)):
            #*********************************************************************
            #                      CODIFICACIÃ“N DE VENTANAS                      *
            #*********************************************************************
              vA=get_coordenadas(va)
              vR=get_coordenadas(vr)
              
              # print(contact)
              redondeado = round(ra, 3)
              

              if (clase[3]!=0 or redondeado<0.3):
                
                if(clase[0]==1):
                  clase_1 += 1

                if(clase[1]==1):
                  clase_2 +=1

                if(clase[2]==1):
                  clase_3 += 1

                if(clase[3]==1):
                  clase_4 += 1

            #*********************************************************************
            #                      CREACION DE DATASET                           *
            #*********************************************************************
                vaStr=''.join(map(str, SVA))
                propertiesVa=getCompositionR(vaStr)              
                #print("propertiesVa: "+str(len(propertiesVa)))
                vrStr=''.join(map(str, SVR))
                propertiesVr=getCompositionR(vrStr)
                #print("propertiesVr: "+str(len(propertiesVr)))

                pssm=getPssm(vaStr,vrStr)
                #time.sleep(5)
                # propiedadesVa.append(listaVa) importante: listaVa=propertiesVa
                # propiedadesVr.append(listaVr)

                # contacto.append(contact)

                matricesVa=crear_matrices(vA)
                
                matricesVa= np.array(matricesVa)
                
                # f = open("/content/drive/MyDrive/Tesis/matrices.txt", "a")
                # for l in matricesVa:
                #   f.write(str(l))
                  
                #print("matricesVa: "+str(len(matricesVa)))
                
                #print(my_pssm)
                matricesVa=np.stack(matricesVa, axis=2).flatten()
                
                matricesVr=crear_matrices(vR)
                matricesVr = np.array(matricesVr)              
                matricesVr=np.stack(matricesVr, axis=2).flatten()          


                se=serialize_example(matricesVa, matricesVr, distancia, propertiesVa,propertiesVr,pssm,clase)
                file_writer.write(se) 
      except:
        print("PROTEIN ERROR")
    # dataset=tf.data.TFRecordDataset([path]).map(decode_fn)
    # batch=dataset.batch(4)
  
  print("Clase_1: "+str(clase_1))
  print("Clase_2: "+str(clase_2))
  print("Clase_3: "+str(clase_3))
  print("Clase_4: "+str(clase_4))
    # for i,record in enumerate(batch):
    #     print(i,record['matricesVa'])
    # dataset = tf.data.Dataset.from_tensor_slices({"matricesvA":listMaVa,"matricesvR":listMaVr,"contacto":contacto,"distancia":listDis,"ScaleVA":propiedadesVa,"ScaleVR":propiedadesVr})  
    # tf.data.experimental.save(dataset, path) 
    
    




if __name__ == '__main__':
    main()