# -*- coding: utf-8 -*-
"""CreateModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TDHsDZoLt44xZnayxYuinByXTOlxq6AU
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow==2.9
!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2

import tensorflow as tf
from keras import Model
from keras.layers.core import Dense, Flatten,Dropout, Activation
from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D
from keras.layers import Input, BatchNormalization, Add
from sklearn.model_selection import train_test_split


print("Load database")

#Decode Function
def decode_fn(record_bytes):
  return tf.io.parse_single_example(
      record_bytes,
      {'matricesVa': tf.io.FixedLenFeature((21,21,7), dtype=tf.float32),
       'matricesVr': tf.io.FixedLenFeature((21,21,7), dtype=tf.float32),
       'distancia':  tf.io.FixedLenFeature(1, dtype=tf.float32),
       'propertiesVa': tf.io.FixedLenFeature(8, dtype=tf.float32),
       'propertiesVr': tf.io.FixedLenFeature(8, dtype=tf.float32),
       'pssm':tf.io.FixedLenFeature((22,19,1),dtype=tf.float32),
       'clase':tf.io.FixedLenFeature(4, dtype=tf.float32)       
       }
  )

#Preprocesamiento retorna diccionario datos para entrenamiento y test
def preprocessing(dataset):
  train={}
  test={}
  Y_train=[]
  Y_test={}

  X=dataset['matricesVa']
  X=X.numpy()
  
  M=dataset['matricesVr']
  M=M.numpy()
  
  D=dataset['distancia']
  D=D.numpy()
  SVA=dataset['propertiesVa']
  SVA=SVA.numpy()

  SVR=dataset['propertiesVr']
  SVR=SVR.numpy()
  pssm=dataset['pssm']
  pssm=pssm.numpy()
  clase=dataset['clase']
  clase=clase.numpy()

  X_train, X_test,M_train,M_test,D_train,D_test,SVA_train,SVA_test,SVR_train,SVR_test,pssm_train,pssm_test,clase_train,clase_test = train_test_split(X,M,D,SVA,SVR,pssm,clase,test_size=.3)  
  
  train['matricesVa']=X_train
  train['matricesVr']=M_train
  train['distancia']=D_train
  train['propertiesVa']=SVA_train
  train['propertiesVr']=SVR_train
  train['pssm']=pssm_train
  
  Y_train=clase_train

  test['matricesVa']=X_test
  test['matricesVr']=M_test
  test['distancia']=D_test
  test['propertiesVa']=SVA_test
  test['propertiesVr']=SVR_test
  test['pssm']=pssm_test
  
  Y_test=clase_test
 
  return train,Y_train,test,Y_test

#Funci√≥n que construye la rna profunda
def cnn():

  matriz_a = tf.keras.Input(shape=(21,21,7), name='matricesVa')
  matriz_b = tf.keras.Input(shape=(21,21,7), name='matricesVr')
  distance = tf.keras.Input(shape=(1,), name='distancia')
  SVA=tf.keras.Input(shape=(8,),name='propertiesVa')
  SVR=tf.keras.Input(shape=(8,),name='propertiesVr')
  pssmatrix = tf.keras.Input(shape=(22,19,1),name='pssm')
  
  # Save the input value. We'll need this later to add back to the main path. 
  X= matriz_a
  Y= matriz_b

  X_shortcut = X
  Y_shortcut = Y
  pssm_shortcut=pssmatrix

  '''bloque 1'''
  # First component of resnet block
  X = tf.keras.layers.Conv2D(filters=4, kernel_size=3,strides = (1,1),padding = 'valid')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)
  # Second component of resnet block
  X = tf.keras.layers.Conv2D(filters=4, kernel_size=3,strides = (1,1), padding='same')(X)
  X= BatchNormalization(axis = 3)(X)

  X_shortcut = tf.keras.layers.Conv2D(filters=4, kernel_size=3,strides = (1,1), padding='valid')(X_shortcut)
  X_shortcut = BatchNormalization(axis = 3)(X_shortcut)

  # Final step: Add shortcut value to resnet block
  X = Add()([X, X_shortcut])
  X = Activation('relu')(X)
  
  '''bloque 2'''
  # First component of resnet block
  X = tf.keras.layers.Conv2D(filters=8, kernel_size=3,strides = (1,1),padding = 'valid')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)
  # Second component of resnet block
  X = tf.keras.layers.Conv2D(filters=8, kernel_size=3,strides = (1,1), padding='same')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)
  
  X_shortcut = tf.keras.layers.Conv2D(filters=8, kernel_size=3,strides = (1,1), padding='valid')(X_shortcut)
  X_shortcut = BatchNormalization(axis = 3)(X_shortcut)

  # Final step: Add shortcut value to resnet block
  X = Add()([X, X_shortcut])
  X = Activation('relu')(X)

  '''bloque 3'''
  # First component of resnet block
  X = tf.keras.layers.Conv2D(filters=16, kernel_size=3,strides = (1,1),padding = 'valid')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)
  # Second component of resnet block
  X = tf.keras.layers.Conv2D(filters=16, kernel_size=3,strides = (1,1), padding='same')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)

  X_shortcut = tf.keras.layers.Conv2D(filters=16, kernel_size=3,strides = (1,1), padding='valid')(X_shortcut)
  X_shortcut = BatchNormalization(axis = 3)(X_shortcut)

  # Final step: Add shortcut value to resnet block
  X = Add()([X, X_shortcut])
  X = Activation('relu')(X)

  '''bloque 4'''
  # First component of resnet block
  X = tf.keras.layers.Conv2D(filters=32, kernel_size=3,strides = (1,1),padding = 'valid')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)
  # Second component of resnet block
  X = tf.keras.layers.Conv2D(filters=32, kernel_size=3,strides = (1,1), padding='same',input_shape=(13,13,32))(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)
  X_shortcut = tf.keras.layers.Conv2D(filters=32, kernel_size=3,strides = (1,1), padding='valid',input_shape=(15,15,16))(X_shortcut)
  X_shortcut = BatchNormalization(axis = 3)(X_shortcut)

  # Final step: Add shortcut value to resnet block
  X = Add()([X, X_shortcut])
  X = Activation('relu')(X)

  '''bloque 5'''
  # First component of resnet block
  X = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides = (1,1),padding = 'valid')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)

  # Second component of resnet block
  X = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides = (1,1), padding='same')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)

  X_shortcut = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides = (1,1), padding='valid')(X_shortcut)
  X_shortcut = BatchNormalization(axis = 3)(X_shortcut)

  # Final step: Add shortcut value to resnet block
  X = Add()([X, X_shortcut])
  X = Activation('relu')(X)

  '''bloque 6'''
  # First component of resnet block
  X = tf.keras.layers.Conv2D(filters=128, kernel_size=3,strides = (1,1),padding = 'valid')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)
 
  # Second component of resnet block
  X = tf.keras.layers.Conv2D(filters=128, kernel_size=3,strides = (1,1), padding='same')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)
  
  X_shortcut = tf.keras.layers.Conv2D(filters=128, kernel_size=3,strides = (1,1), padding='valid')(X_shortcut)
  X_shortcut = BatchNormalization(axis = 3)(X_shortcut)

  # Final step: Add shortcut value to resnet block
  X = Add()([X, X_shortcut])
  X = Activation('relu')(X)

  '''bloque 7'''
  # First component of resnet block
  X = tf.keras.layers.Conv2D(filters=256, kernel_size=3,strides = (1,1),padding = 'valid')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)

  # Second component of resnet block
  X = tf.keras.layers.Conv2D(filters=256, kernel_size=3,strides = (1,1), padding='same')(X)
  X= BatchNormalization(axis = 3)(X)
  X = Activation('relu')(X)

  X_shortcut = tf.keras.layers.Conv2D(filters=256, kernel_size=3,strides = (1,1), padding='valid')(X_shortcut)
  X_shortcut = BatchNormalization(axis = 3)(X_shortcut)

  # Final step: Add shortcut value to resnet block
  X = Add()([X, X_shortcut])
  X = Activation('relu')(X)

  '''bloque 1'''
  # First component of resnet block
  Y = tf.keras.layers.Conv2D(filters=4, kernel_size=3,strides = (1,1),padding = 'valid')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)
  
  # Second component of resnet block
  Y = tf.keras.layers.Conv2D(filters=4, kernel_size=3,strides = (1,1), padding='same')(Y)
  Y= BatchNormalization(axis = 3)(Y)

  Y_shortcut = tf.keras.layers.Conv2D(filters=4, kernel_size=3,strides = (1,1), padding='valid')(Y_shortcut)
  Y_shortcut = BatchNormalization(axis = 3)(Y_shortcut)

  # Final step: Add shortcut value to resnet block
  Y = Add()([Y, Y_shortcut])
  Y = Activation('relu')(Y)
  
  '''bloque 2'''
  # First component of resnet block
  Y = tf.keras.layers.Conv2D(filters=8, kernel_size=3,strides = (1,1),padding = 'valid')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)

  Y = tf.keras.layers.Conv2D(filters=8, kernel_size=3,strides = (1,1), padding='same')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)
  
  Y_shortcut = tf.keras.layers.Conv2D(filters=8, kernel_size=3,strides = (1,1), padding='valid')(Y_shortcut)
  Y_shortcut = BatchNormalization(axis = 3)(Y_shortcut)

  # Final step: Add shortcut value to resnet block
  Y = Add()([Y, Y_shortcut])
  Y = Activation('relu')(Y)

  '''bloque 3'''
  # First component of resnet block
  Y = tf.keras.layers.Conv2D(filters=16, kernel_size=3,strides = (1,1),padding = 'valid')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)

  # Second component of resnet block
  Y = tf.keras.layers.Conv2D(filters=16, kernel_size=3,strides = (1,1), padding='same')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)
  
  Y_shortcut = tf.keras.layers.Conv2D(filters=16, kernel_size=3,strides = (1,1), padding='valid')(Y_shortcut)
  Y_shortcut = BatchNormalization(axis = 3)(Y_shortcut)

  # Final step: Add shortcut value to resnet block
  Y = Add()([Y, Y_shortcut])
  Y = Activation('relu')(Y)

  '''bloque 4'''
  # First component of resnet block
  Y = tf.keras.layers.Conv2D(filters=32, kernel_size=3,strides = (1,1),padding = 'valid')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)

  # Second component of resnet block
  Y = tf.keras.layers.Conv2D(filters=32, kernel_size=3,strides = (1,1), padding='same')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)
  
  Y_shortcut = tf.keras.layers.Conv2D(filters=32, kernel_size=3,strides = (1,1), padding='valid')(Y_shortcut)
  Y_shortcut = BatchNormalization(axis = 3)(Y_shortcut)

  # Final step: Add shortcut value to resnet block
  Y = Add()([Y, Y_shortcut])
  Y = Activation('relu')(Y)

  '''bloque 5'''
  # First component of resnet block
  Y = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides = (1,1),padding = 'valid')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)

  # Second component of resnet block
  Y = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides = (1,1), padding='same')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)
  
  Y_shortcut = tf.keras.layers.Conv2D(filters=64, kernel_size=3,strides = (1,1), padding='valid')(Y_shortcut)
  Y_shortcut = BatchNormalization(axis = 3)(Y_shortcut)

  # Final step: Add shortcut value to resnet block
  Y = Add()([Y, Y_shortcut])
  Y = Activation('relu')(Y)

  '''bloque 6'''
  # First component of resnet block
  Y = tf.keras.layers.Conv2D(filters=128, kernel_size=3,strides = (1,1),padding = 'valid')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)

  # Second component of resnet block
  Y = tf.keras.layers.Conv2D(filters=128, kernel_size=3,strides = (1,1), padding='same')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)

  Y_shortcut = tf.keras.layers.Conv2D(filters=128, kernel_size=3,strides = (1,1), padding='valid')(Y_shortcut)
  Y_shortcut = BatchNormalization(axis = 3)(Y_shortcut)

  # Final step: Add shortcut value to resnet block
  Y = Add()([Y, Y_shortcut])
  Y = Activation('relu')(Y)


  '''bloque 7'''
  # First component of resnet block
  Y = tf.keras.layers.Conv2D(filters=256, kernel_size=3,strides = (1,1),padding = 'valid')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)
 
  # Second component of resnet block
  Y = tf.keras.layers.Conv2D(filters=256, kernel_size=3,strides = (1,1), padding='same')(Y)
  Y= BatchNormalization(axis = 3)(Y)
  Y = Activation('relu')(Y)

  Y_shortcut = tf.keras.layers.Conv2D(filters=256, kernel_size=3,strides = (1,1), padding='valid')(Y_shortcut)
  Y_shortcut = BatchNormalization(axis = 3)(Y_shortcut)

  # Final step: Add shortcut value to resnet block
  Y = Add()([Y, Y_shortcut])
  Y = Activation('relu')(Y)

  # PSSM
  '''bloque 1'''
  # First component of resnet block
  pssm = tf.keras.layers.Conv2D(filters=4, kernel_size=3,strides = (1,1),padding = 'valid')(pssmatrix)
  pssm= BatchNormalization(axis = 3)(pssm)
  pssm = Activation('relu')(pssm)
  # Second component of resnet block
  pssm = tf.keras.layers.Conv2D(filters=4, kernel_size=3,strides = (1,1), padding='same')(pssm)
  pssm= BatchNormalization(axis = 3)(pssm)

  pssm_shortcut = tf.keras.layers.Conv2D(filters=4, kernel_size=3,strides = (1,1), padding='valid')(pssm_shortcut)
  pssm_shortcut = BatchNormalization(axis = 3)(pssm_shortcut)

  # Final step: Add shortcut value to resnet block
  pssm = Add()([pssm, pssm_shortcut])
  pssm = Activation('relu')(pssm)
  
  '''bloque 2'''
  # First component of resnet block
  pssm = tf.keras.layers.Conv2D(filters=8, kernel_size=3,strides = (1,1),padding = 'valid')(pssm)
  pssm= BatchNormalization(axis = 3)(pssm)
  pssm = Activation('relu')(pssm)
  # Second component of resnet block
  pssm = tf.keras.layers.Conv2D(filters=8, kernel_size=3,strides = (1,1), padding='same',input_shape=(17,17,8))(pssm)
  pssm= BatchNormalization(axis = 3)(pssm)
  pssm = Activation('relu')(pssm)
  
  pssm_shortcut = tf.keras.layers.Conv2D(filters=8, kernel_size=3,strides = (1,1), padding='valid',input_shape=(19,19,4))(pssm_shortcut)
  pssm_shortcut = BatchNormalization(axis = 3)(pssm_shortcut)

  # Final step: Add shortcut value to resnet block
  pssm = Add()([pssm, pssm_shortcut])
  pssm = Activation('relu')(pssm)

  '''bloque 3'''
  # First component of resnet block
  pssm = tf.keras.layers.Conv2D(filters=16, kernel_size=3,strides = (1,1),padding = 'valid')(pssm)
  pssm= BatchNormalization(axis = 3)(pssm)
  pssm = Activation('relu')(pssm)
  # Second component of resnet block
  pssm = tf.keras.layers.Conv2D(filters=16, kernel_size=3,strides = (1,1), padding='same')(pssm)
  pssm= BatchNormalization(axis = 3)(pssm)
  pssm = Activation('relu')(pssm)
  
  pssm_shortcut = tf.keras.layers.Conv2D(filters=16, kernel_size=3,strides = (1,1), padding='valid')(pssm_shortcut)
  pssm_shortcut = BatchNormalization(axis = 3)(pssm_shortcut)

  # Final step: Add shortcut value to resnet block
  pssm = Add()([pssm, pssm_shortcut])
  pssm = Activation('relu')(pssm)

  '''bloque 4'''
  # First component of resnet block
  pssm = tf.keras.layers.Conv2D(filters=32, kernel_size=3,strides = (1,1),padding = 'valid')(pssm)
  pssm= BatchNormalization(axis = 3)(pssm)
  pssm = Activation('relu')(pssm)
  # Second component of resnet block
  pssm = tf.keras.layers.Conv2D(filters=32, kernel_size=3,strides = (1,1), padding='same')(pssm)
  pssm= BatchNormalization(axis = 3)(pssm)
  pssm = Activation('relu')(pssm)
  
  pssm_shortcut = tf.keras.layers.Conv2D(filters=32, kernel_size=3,strides = (1,1), padding='valid')(pssm_shortcut)
  pssm_shortcut = BatchNormalization(axis = 3)(pssm_shortcut)

  # Final step: Add shortcut value to resnet block
  pssm = Add()([pssm, pssm_shortcut])
  pssm = Activation('relu')(pssm)

  pssm=MaxPooling2D(pool_size=(2, 2))(pssm)
  
  pssm=MaxPooling2D(pool_size=(2, 2))(pssm)   

  pssm=MaxPooling2D(pool_size=(2, 2))(pssm)   
 
  pssm=Flatten()(pssm)
  
  contact_features = tf.keras.layers.concatenate([X,Y],axis=3)
 
  #contact features
  '''bloque 1'''
  # First component of resnet block
  contact_features = tf.keras.layers.Conv2D(filters=1024, kernel_size=3,strides = (1,1),padding = 'valid')(contact_features)
  contact_features= BatchNormalization(axis = 3)(contact_features)
  contact_features = Activation('relu')(contact_features)
  # Second component of resnet block
  contact_features = tf.keras.layers.Conv2D(filters=2048, kernel_size=3,strides = (1,1), padding='valid')(contact_features)
  contact_features= BatchNormalization(axis = 3)(contact_features)
  contact_features = Activation('relu')(contact_features)
  
  contact_features=MaxPooling2D(pool_size=(2, 2))(contact_features)
  contact_features = Flatten()(contact_features)
  print("Maxpooling: "+str(contact_features.shape))
  contact_features = tf.keras.layers.concatenate([contact_features,distance,SVA,SVR,pssm],axis=1)
  print("contact_features: ")
  print(contact_features.shape)

  contact_features = Dense(128,activation='relu')(contact_features)
  contact_features = Dense(64,activation='relu')(contact_features)
  contact_features = Dense(32,activation='relu')(contact_features)
  contact_features = Dense(16,activation='relu')(contact_features)
  contact_features = Dense(8,activation='relu')(contact_features)
  contact_features = Dense(4,activation='softmax')(contact_features)

  model = Model(inputs = [matriz_a,matriz_b,distance,SVA,SVR,pssmatrix], outputs = [contact_features], name='ClassNet')
  model.summary()

  return model


model=cnn()
opt = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy','Recall','Precision','AUC'])

#f = open("/content/drive/MyDrive/Tesis/metricas80-1N.txt", "w")
path="/content/drive/MyDrive/Tesis/dataset1000Protein.dat"
dataset=tf.data.TFRecordDataset([path]).map(decode_fn)
reader=dataset.batch(4096)

for i,record in enumerate(reader):
  print("Processing batch: ",i)
  
  X_train,Y_train,X_test,Y_test=preprocessing(record)

  for epoch in range (0,25,1):
    train=model.train_on_batch(X_train,Y_train)
    print(epoch,train)
  test=model.test_on_batch(X_test,Y_test)
  print('Test metric',test)
  
  f.write(str(test))

# Save model
f.close()
model.save('/content/drive/MyDrive/Tesis/Model1000Protein-25-1N.h5')
